{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4YrQoL4p7RjB",
        "UmF6pgVXugc1"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeanferreiraufu/python-data-transformation/blob/develop/PGC302B_Atividade_Jean_Ferreira_Henrique_Moreira_Amorim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Atividade Curricular da Disciplina PGC302B**\n",
        "\n",
        "*   Disciplina: Sistemas para Processamento Multim√≠dia\n",
        "*   Professor: Dr. Marcelo Zanchetta do Nascimento\n",
        "*   Discentes: Jean Carlo Alves Ferreira e Henrique Moreira Amorim.\n",
        "*   Universidade Federal de Uberl√¢ndia\n",
        "*   Programa de P√≥s-Gradua√ß√£o em Computa√ß√£o"
      ],
      "metadata": {
        "id": "4YrQoL4p7RjB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Especifica√ß√£o do Problema:**\n",
        "\n",
        "O objetivo deste trabalho √© analisar os m√©todos empregados em etapas de processamento da m√≠dia imagem. Vamos analisar as estrat√©gias empregadas na etapa de segmenta√ß√£o e extra√ß√£o de caracter√≠sticas das imagens. Ser√° investigado o m√©todo mais robusto para a etapa de segmenta√ß√£o baseado em segmenta√ß√£o por similaridade. Em seguida, explorado um algoritmo de extra√ß√£o de caracter√≠sticas baseado em propriedades de textura. As implementa√ß√µes devem ocorrer em ambiente Google CoLab com a linguagem de programa√ß√£o Python.\n",
        "\n",
        "$\\space$\n",
        "$\\space$\n",
        "\n",
        "\n",
        "**Dataset**\n",
        "\n",
        "O dataset que iremos empregar neste estudo foi proposto por Ghaderzadeh, M, Aria, M, Hosseini, A, Asadi, F, Bashash, D, Abolghasemi, H. A fast and efficient CNN model for B-ALL diagnosis and its subtypes classification using peripheral blood smear images. Int J Intell Syst. 2022; 37: 5113- 5133. doi:10.1002/int.22753.\n",
        "\n",
        "As imagens desse conjunto de dados foram preparadas no laborat√≥rio de medula √≥ssea do Hospital Taleqani (Teer√£). Esse conjunto de dados consiste em 3.256 imagens de manchas de sangue perif√©rico (PBS) de 89 pacientes com suspeita de leucemia linfobl√°stica aguda (LLA), cujas amostras de sangue foram preparadas e coradas por uma equipe de laborat√≥rio. Esse conjunto de dados foi dividido em duas classes: benigna e maligna. A primeira compreende hematog√¥nias que se assemelham muito aos casos de LLA, entretanto, essa c√©lula precursora hematopoi√©tica √© benigna, n√£o requer quimioterapia. O grupo de LLA com tr√™s subtipos de linfoblastos malignos: LLA pr√©-B inicial, pr√©-B e pr√≥-B. Todas as imagens foram obtidas com uma c√¢mera Zeiss em um microsc√≥pio com amplia√ß√£o de 100 vezes e salvas como arquivos JPG. Um especialista que utilizou a ferramenta de citometria de fluxo fez a marca√ß√£o do padr√£o ouro dos tipos e subtipos dessas c√©lulas.\n",
        "\n",
        "O dataset esta dispon√≠vel no link: https://www.kaggle.com/datasets/mehradaria/leukemia/data.\n",
        "\n",
        "$\\space$\n",
        "$\\space$\n",
        "\n",
        "\n",
        "**Segmenta√ß√£o**\n",
        "\n",
        "Em nossa disciplina, apresentamos t√©cnicas de segmenta√ß√£o baseadas em similiaridade (thresholding - limiariza√ß√£o) para processos sobre a m√≠dia imagem.\n",
        "\n",
        "1) Implemente um programa para segmenta√ß√£o de imagens baseado em limiariza√ß√£o adaptativa local para separa√ß√£o dos objetos em rela√ß√£o a regi√£o de fundo. Procure explorar os modelos de cores (RGB, HSV, etc) para investigar o desempenho sobre os diferentes modelos. O c√≥digo desse algoritmo deve ser implementado sem usar fun√ß√µes dispon√≠veis em bibliotecas da linguagem.\n",
        "\n",
        "2) Em seguida, usando a biblioteca OpenCV, fa√ßa a implementa√ß√£o da limiariza√ß√£o de Otsu. Fa√ßa uma investiga√ß√£o sobre diferentes bibliotecas Python para processamento de imagem e escolha duas outras t√©cnicas de limiariza√ß√£o dispon√≠veis para uma compara√ß√£o entre os m√©todos.\n",
        "\n",
        "3) Fa√ßa a aplica√ß√£o das diversas t√©cnicas sobre o conjunto de imagens proposto para o estudo.\n",
        "\n",
        "4) Avalie os resultados em rela√ß√£o as m√°scaras dispon√≠veis na pasta \"Segmented\". Obtenha os valores das m√©tricas IoU (Intersection over Union) e coeficiente Dice usadas em segmenta√ß√£o.\n",
        "\n",
        "A m√©trica IoU mede a sobreposi√ß√£o entre a √°rea prevista e a √°rea real:\n",
        "\n",
        "$\\text{IoU} = \\frac{|A \\cap B|}{|A \\cup B|}$\n",
        "\n",
        "Onde:\n",
        "ùê¥ - √© o conjunto de pixels da segmenta√ß√£o prevista, ùêµ - √© o conjunto de pixels da segmenta√ß√£o verdadeira, ‚à© - representa a interse√ß√£o dos conjuntos e ‚à™ - representa a uni√£o dos conjuntos.\n",
        "\n",
        "O coeficiente de Dice mede a similaridade entre dois conjuntos, o qual √© dado por:\n",
        "\n",
        "$\\text{Dice} = \\frac{2 |A \\cap B|}{|A| + |B|}$\n",
        "\n",
        "Onde: ùê¥ - √© o conjunto de pixels da segmenta√ß√£o prevista, ùêµ - √© o conjunto de pixels da segmenta√ß√£o verdadeira e ‚à© representa a interse√ß√£o dos conjuntos.\n",
        "\n",
        "5) Use t√©cnicas estat√≠sticas que quantificam o desempenho dos modelos de segmenta√ß√£o para uma compara√ß√£o dos resultados. Para as compara√ß√µes entre modelos, voc√™ pode usar os intervalos de confian√ßa ou ANOVA. Tamb√©m pode ser considerado os testes n√£o param√©tricos (Wilcoxon, Mann-Whitney).\n",
        "\n",
        "$\\space$\n",
        "$\\space$\n",
        "\n",
        "**Extra√ß√£o de Caracter√≠sticas**\n",
        "\n",
        "6) Crie um programa que leia as imagens do dataset sem segmenta√ß√£o e calcule a matriz de coocorr√™ncia numa representa√ß√£o de 256 n√≠veis de intensidades. Como as imagens est√£o em RGB fa√ßa a convers√£o para n√≠veis de cinza. Use as orienta√ß√µes de 0, 45, 90 e 135 graus com d = 1, d = 2, d = 3 e d = 4. Calcule a m√©dia e o desvio padr√£o das matrizes.\n",
        "\n",
        "7) Utilize as matrizes de coocorr√™ncia e calcule 5 principais descritores propostos por Haralick.\n",
        "\n",
        "8) Fa√ßa uma an√°lise de similaridade entre as classes investigadas por meio de caracter√≠sticas extra√≠das com os descritores e a varia√ß√£o de parametriza√ß√£o. Para essa an√°lise, use a similaridade de Jaccard e o coeficiente de correla√ß√£o de Pearson.\n",
        "\n",
        "A similaridade de Jaccard pode ser aplicada diretamente se voc√™ tratar os descritores de Haralick como conjuntos de valores binarizados ou discreto:\n",
        "\n",
        "$J(A, B) = \\frac{|A \\cap B|}{|A \\cup B|}$\n",
        "\n",
        "onde: ‚à£A‚à©B‚à£‚à£A‚à©B‚à£ √© o tamanho da interse√ß√£o entre AA e BB, e ‚à£A‚à™B‚à£‚à£A‚à™B‚à£ √© o tamanho da uni√£o dos conjuntos AA e BB.\n",
        "\n",
        "coeficiente de correla√ß√£o de Pearson:\n",
        "\n",
        "$ r = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\\sqrt{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}}$\n",
        "\n",
        "onde, x e y s√£o as duas vari√°veis, n √© o n√∫mero de observa√ß√µes, xÃÑ e »≥ s√£o as m√©dias de x e y, respectivamente.\n",
        "\n",
        "9) Discuta os resultados e as observa√ß√µes em rela√ß√£o as varia√ß√µes de par√¢metros e a representa√ß√£o pela t√©cnica para as classes investigadas.\n",
        "\n",
        "10) Repita esses experimentos sobre as imagens segmentadas com a melhor resultado da t√©cnica de segmenta√ß√£o obtida na etapa 5). Avalie o comportamento dos descritores com informa√ß√µes segmentadas. Fa√ßa discuss√µes semelhantes as observa√ß√µes obtidas na quest√£o 9) com as imagens segmentadas.\n",
        "\n",
        "\n",
        "$\\space$\n",
        "$\\space$\n",
        "\n",
        "\n",
        "**Entrega**\n",
        "\n",
        "\n",
        "O trabalho deve ser submetido por meio da plataforma Microsoft Teams.\n",
        "\n",
        "Data de entrega: **23/10/2024**\n",
        "\n",
        "Essa atividade pode ser realizada em grupos de dois estudantes, os quais dever√£o submeter o relat√≥rio pela plataforma Teams.\n",
        "\n",
        "A entrega do trabalho deve conter os seguintes itens:\n",
        "* codigo-fonte: o arquivo final deve estar no formato .zip ou no formato tgz, contendo todos os programas ou dados necessarios para sua execu√ß√£o. Tamb√©m deve ter um cabe√ßalho com os dados dos estudantes (Nome e Matr√≠cula).\n",
        "* relatorio: deve conter uma descri√ß√£o dos algoritmos e das estruturas de dados, considera√ß√µes adotadas na solu√ß√£o do problema, testes executados, eventuais limita√ß√µes ou situa√ß√µes especiais n√£o explorada pelo programa.\n"
      ],
      "metadata": {
        "id": "LH54jwws8rF9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exerc√≠cio 1 - Proposta\n",
        "\n",
        "\n",
        "1.   A segmenta√ß√£o adaptativa no espa√ßo HSV mostrou-se a mais promissora, especialmente quando aplicada no canal de brilho V.\n",
        "2.   A extra√ß√£o de caracter√≠sticas de textura, especialmente via GLCM, √© essencial para avaliar a precis√£o da segmenta√ß√£o e ajudar na classifica√ß√£o das c√©lulas.\n",
        "3.   A combina√ß√£o de diferentes espa√ßos de cores (HSV, YUV, RGB) oferece uma abordagem robusta para lidar com varia√ß√µes de ilumina√ß√£o e cor nas imagens.\n",
        "4.   A avalia√ß√£o baseada em m√©tricas como IoU e F1-score garante a valida√ß√£o da qualidade da segmenta√ß√£o e da extra√ß√£o de caracter√≠sticas."
      ],
      "metadata": {
        "id": "UmF6pgVXugc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "osg38hHH-3Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Passo 1: Carregar o Dataset\n",
        "\n",
        "Etapas para baixar o dataset do Kakgle:\n",
        "Obter o kaggle.json:\n",
        "\n",
        "Acesse sua conta no Kaggle, v√° at√© \"My Account\", e role at√© a se√ß√£o \"API\".\n",
        "Clique em \"Create New API Token\". Isso far√° o download do arquivo kaggle.json contendo suas credenciais.\n",
        "Carregar o arquivo kaggle.json no Google Colab:\n",
        "\n",
        "No Google Colab, voc√™ pode carregar o arquivo kaggle.json clicando em \"Arquivos\" (na barra lateral) e depois em \"Upload\". Selecione o arquivo kaggle.json que voc√™ baixou.\n",
        "Corrigir o caminho e permiss√µes para o kaggle.json:\n",
        "\n",
        "Ap√≥s o upload, voc√™ precisa mover o arquivo para o diret√≥rio correto."
      ],
      "metadata": {
        "id": "Ju9x0edEvKIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload manual do kaggle.json\n",
        "from google.colab import files\n",
        "files.upload()  # Fa√ßa o upload do arquivo kaggle.json que foi baixado do Kaggle\n",
        "\n",
        "# Mover o kaggle.json para o diret√≥rio correto\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "\n",
        "# Definir permiss√µes corretas\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Baixar o dataset do Kaggle\n",
        "!kaggle datasets download -d mehradaria/leukemia\n",
        "\n",
        "# Descompactar o arquivo baixado\n",
        "!unzip leukemia.zip -d leukemia_dataset\n"
      ],
      "metadata": {
        "id": "RGjAngUAvSTX",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Passo 2: Importar as Bibliotecas Necess√°rias"
      ],
      "metadata": {
        "id": "kdDAMCajvXa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar bibliotecas necess√°rias para processamento de imagens\n",
        "!pip install opencv-python-headless\n",
        "!pip install scikit-image\n",
        "!pip install matplotlib\n"
      ],
      "metadata": {
        "id": "Ka94hV404bUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np  # NumPy para opera√ß√µes matriciais\n",
        "import matplotlib.pyplot as plt  # Matplotlib para visualiza√ß√£o\n",
        "import pandas as pd  # Pandas para visualiza√ß√£o data frame\n",
        "\n",
        "# Para extra√ß√£o de caracter√≠sticas de textura\n",
        "from skimage.feature import graycomatrix # Corrected function name to graycomatrix\n",
        "from skimage.feature import graycoprops # Corrected function name to graycoprops\n",
        "from skimage.color import rgb2gray\n",
        "from skimage import img_as_ubyte\n",
        "\n"
      ],
      "metadata": {
        "id": "txTAVuCvvakz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "files=[]\n",
        "paths = []\n",
        "for dirname, _, filenames in os.walk('leukemia_dataset/Original'):\n",
        "    for filename in filenames:\n",
        "        path = os.path.join(dirname, filename)\n",
        "        paths.append(path)\n",
        "        files.append(filename)\n",
        "\n",
        "mpaths = []\n",
        "for dirname, _, filenames in os.walk('leukemia_dataset/Segmented'):\n",
        "    for filename in filenames:\n",
        "        path = os.path.join(dirname, filename)\n",
        "        mpaths.append(path)\n",
        "\n",
        "df0=pd.DataFrame(columns=['file','path','mpath'])\n",
        "df0['file']=sorted(files)\n",
        "df0['path']=sorted(paths)\n",
        "df0['mpath']=sorted(mpaths)\n",
        "display(df0)\n",
        "df=df0.iloc[0:len(df0)//2]\n",
        "test_df=df0.iloc[len(df0)//2:]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0UpZ3ZglMyhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Passo 3: Implementar a Segmenta√ß√£o por Limiariza√ß√£o Adaptativa\n",
        "A segmenta√ß√£o ser√° realizada no canal V do espa√ßo de cor HSV.\n",
        "\n",
        "Vamos implementar a limiariza√ß√£o adaptativa localmente.\n",
        "\n",
        "    ** Convers√£o de RGB para HSV\n",
        "        O espa√ßo de cor HSV (Matiz, Satura√ß√£o e Valor) √© uma representa√ß√£o alternativa ao RGB (Vermelho, Verde e Azul) que facilita a compreens√£o das cores em termos de seu tom (matiz), intensidade (valor) e satura√ß√£o. A convers√£o entre os espa√ßos de cor RGB e HSV pode ser feita em etapas matem√°ticas.\n",
        "\n",
        "        Fun√ß√£o rgb_to_hsv(r, g, b): Converte os valores RGB para o espa√ßo de cor HSV.\n",
        "\n",
        "    Esse c√≥digo n√£o utiliza bibliotecas como OpenCV, calculando a convers√£o entre os dois espa√ßos de cor apenas com opera√ß√µes matem√°ticas b√°sicas."
      ],
      "metadata": {
        "id": "T7QIQB6YvkH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rgb_to_hsv(r, g, b):\n",
        "    # Normalizar os valores de R, G, B para [0, 1]\n",
        "    r_prime, g_prime, b_prime = r / 255.0, g / 255.0, b / 255.0\n",
        "\n",
        "    # Encontrar o m√°ximo e o m√≠nimo entre os valores normalizados\n",
        "    c_max = max(r_prime, g_prime, b_prime)\n",
        "    c_min = min(r_prime, g_prime, b_prime)\n",
        "    delta = c_max - c_min\n",
        "\n",
        "    # Valor (V)\n",
        "    v = c_max\n",
        "\n",
        "    # Satura√ß√£o (S)\n",
        "    s = 0 if c_max == 0 else delta / c_max\n",
        "\n",
        "    # Matiz (H)\n",
        "    if delta == 0:\n",
        "        h = 0\n",
        "    elif c_max == r_prime:\n",
        "        h = 60 * (((g_prime - b_prime) / delta) % 6)\n",
        "    elif c_max == g_prime:\n",
        "        h = 60 * (((b_prime - r_prime) / delta) + 2)\n",
        "    elif c_max == b_prime:\n",
        "        h = 60 * (((r_prime - g_prime) / delta) + 4)\n",
        "\n",
        "    if h < 0:\n",
        "        h += 360\n",
        "\n",
        "    return h, s, v\n",
        "\n",
        "# Fun√ß√£o para aplicar a limiariza√ß√£o adaptativa\n",
        "def adaptive_threshold_segmentation_hsv(v_channel, block_size=15, c=2):\n",
        "    padded_image = np.pad(v_channel, block_size // 2, mode='reflect')\n",
        "    thresholded_image = np.zeros_like(v_channel)\n",
        "    for i in range(v_channel.shape[0]):\n",
        "        for j in range(v_channel.shape[1]):\n",
        "            local_region = padded_image[i:i + block_size, j:j + block_size]\n",
        "            local_mean = np.mean(local_region)\n",
        "            threshold = local_mean - c\n",
        "            thresholded_image[i, j] = 255 if v_channel[i, j] > threshold else 0\n",
        "    return thresholded_image\n",
        "\n",
        "# Carregar a imagem usando PIL\n",
        "image_path = 'leukemia_dataset/Original/Benign/WBC-Benign-001.jpg'  # Exemplo de uma imagem\n",
        "image = Image.open(image_path)\n",
        "image_rgb = np.array(image)\n",
        "\n",
        "# Converter a imagem para o espa√ßo de cor HSV e escalar o canal V para o intervalo [0, 255]\n",
        "hsv_image = np.zeros_like(image_rgb, dtype=float)\n",
        "for i in range(image_rgb.shape[0]):\n",
        "    for j in range(image_rgb.shape[1]):\n",
        "        r, g, b = image_rgb[i, j]\n",
        "        h, s, v = rgb_to_hsv(r, g, b)\n",
        "        hsv_image[i, j] = [h, s, v * 255]  # Multiplicar o canal V por 255\n",
        "\n",
        "# Extrair o canal V (brilho)\n",
        "v_channel = hsv_image[:, :, 2]\n",
        "\n",
        "# Aplicar a limiariza√ß√£o adaptativa no canal V\n",
        "segmented_image_hsv = adaptive_threshold_hsv(v_channel)\n",
        "\n",
        "# Exibir a imagem original e a segmentada\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image_rgb)\n",
        "plt.title('Imagem Original')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(segmented_image_hsv, cmap='gray')\n",
        "plt.title('Imagem Segmentada (HSV)')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8Kx0J8uhvdyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Fun√ß√£o rgb_to_yuv(r, g, b): Converte os valores RGB para o espa√ßo de cor YUV."
      ],
      "metadata": {
        "id": "UmFAgYmobLnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√£o para converter RGB para YUV\n",
        "def rgb_to_yuv(r, g, b):\n",
        "    y = 0.299 * r + 0.587 * g + 0.114 * b\n",
        "    u = -0.14713 * r - 0.28886 * g + 0.436 * b\n",
        "    v = 0.615 * r - 0.51499 * g - 0.10001 * b\n",
        "    return y, u, v\n",
        "\n",
        "# Converter a imagem para o espa√ßo de cor YUV\n",
        "def convert_image_rgb_to_yuv(image_rgb):\n",
        "  yuv_image = np.zeros_like(image_rgb, dtype=float)\n",
        "  for i in range(image_rgb.shape[0]):\n",
        "      for j in range(image_rgb.shape[1]):\n",
        "          r, g, b = image_rgb[i, j]\n",
        "          y, u, v = rgb_to_yuv(r, g, b)\n",
        "          yuv_image[i, j] = [y, u, v]\n",
        "\n",
        "  # Extrair o canal Y (lumin√¢ncia)\n",
        "  y_channel = yuv_image[:, :, 0]\n",
        "  return y_channel\n",
        "\n",
        "# Fun√ß√£o para aplicar a limiariza√ß√£o adaptativa\n",
        "def adaptive_threshold_segmentation_yuv(image_rgb, block_size=15, c=2):\n",
        "    y_channel = convert_image_rgb_to_yuv(image_rgb)\n",
        "    padded_image = np.pad(y_channel, block_size // 2, mode='reflect')\n",
        "    thresholded_image = np.zeros_like(y_channel)\n",
        "    for i in range(y_channel.shape[0]):\n",
        "        for j in range(y_channel.shape[1]):\n",
        "            local_region = padded_image[i:i + block_size, j:j + block_size]\n",
        "            local_mean = np.mean(local_region)\n",
        "            threshold = local_mean - c\n",
        "            thresholded_image[i, j] = 255 if y_channel[i, j] > threshold else 0\n",
        "    return thresholded_image\n",
        "\n",
        "# Carregar a imagem usando PIL\n",
        "image_path = 'leukemia_dataset/Original/Benign/WBC-Benign-001.jpg'  # Exemplo de uma imagem\n",
        "image = Image.open(image_path)\n",
        "image_rgb = np.array(image)\n",
        "segmented_image_yuv = adaptive_threshold_segmentation_yuv(image_rgb)\n",
        "\n",
        "# Exibir a imagem original e a segmentada\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image_rgb)\n",
        "plt.title('Imagem Original')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(segmented_image_yuv, cmap='gray')\n",
        "plt.title('Imagem Segmentada (YUV)')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nw5v4bJ6NxY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import cv2  # cv2 para gravacao da imagem segmentada.\n",
        "# Fun√ß√£o para processar e salvar as imagens segmentadas\n",
        "def process_and_save_images(input_dir, output_dir_hsv, output_dir_yuv):\n",
        "    # Verificar se os diret√≥rios de sa√≠da existem, se n√£o, criar\n",
        "    Path(output_dir_hsv).mkdir(parents=True, exist_ok=True)\n",
        "    Path(output_dir_yuv).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Iterar por todas as imagens no diret√≥rio de entrada\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "            image_path = os.path.join(input_dir, filename)\n",
        "            # image = cv2.imread(image_path)\n",
        "            # image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            image = Image.open(image_path)\n",
        "            image_rgb = np.array(image)\n",
        "\n",
        "            # Segmentar a imagem em HSV\n",
        "            segmented_hsv = adaptive_threshold_segmentation_hsv(image_rgb)\n",
        "            segmented_hsv_path = os.path.join(output_dir_hsv, filename)\n",
        "            # Usa CV2 para gravar imagem segmentada com HSV no diretorio\n",
        "            cv2.imwrite(segmented_hsv_path, segmented_hsv)\n",
        "\n",
        "            # Segmentar a imagem em YUV\n",
        "            segmented_yuv = adaptive_threshold_segmentation_yuv(image_rgb)\n",
        "            segmented_yuv_path = os.path.join(output_dir_yuv, filename)\n",
        "            # Usa CV2 para gravar imagem segmentada com YUV no diretorio\n",
        "            cv2.imwrite(segmented_yuv_path, segmented_yuv)\n",
        "\n",
        "            print(f\"Processado e salvo: {filename}\")\n",
        "\n",
        "# Definir os caminhos para o diret√≥rio de entrada e os diret√≥rios de sa√≠da\n",
        "input_dir = 'leukemia_dataset/Original/Benign'\n",
        "output_dir_hsv = 'leukemia_dataset/Segmented_HSV/Benign'\n",
        "output_dir_yuv = 'leukemia_dataset/Segmented_YUV/Benign'\n",
        "\n",
        "# Processar as imagens e salvar nos novos diret√≥rios\n",
        "process_and_save_images(input_dir, output_dir_hsv, output_dir_yuv)\n",
        "\n",
        "# Definir os caminhos para o diret√≥rio de entrada e os diret√≥rios de sa√≠da\n",
        "input_dir = 'leukemia_dataset/Original/Early'\n",
        "output_dir_hsv = 'leukemia_dataset/Segmented_HSV/Early'\n",
        "output_dir_yuv = 'leukemia_dataset/Segmented_YUV/Early'\n",
        "\n",
        "# Processar as imagens e salvar nos novos diret√≥rios\n",
        "process_and_save_images(input_dir, output_dir_hsv, output_dir_yuv)\n",
        "\n",
        "# Definir os caminhos para o diret√≥rio de entrada e os diret√≥rios de sa√≠da\n",
        "input_dir = 'leukemia_dataset/Original/Pre'\n",
        "output_dir_hsv = 'leukemia_dataset/Segmented_HSV/Pre'\n",
        "output_dir_yuv = 'leukemia_dataset/Segmented_YUV/Pre'\n",
        "\n",
        "# Processar as imagens e salvar nos novos diret√≥rios\n",
        "process_and_save_images(input_dir, output_dir_hsv, output_dir_yuv)\n",
        "\n",
        "# Definir os caminhos para o diret√≥rio de entrada e os diret√≥rios de sa√≠da\n",
        "input_dir = 'leukemia_dataset/Original/Pre'\n",
        "output_dir_hsv = 'leukemia_dataset/Segmented_HSV/Pro'\n",
        "output_dir_yuv = 'leukemia_dataset/Segmented_YUV/Pro'\n",
        "\n",
        "# Processar as imagens e salvar nos novos diret√≥rios\n",
        "process_and_save_images(input_dir, output_dir_hsv, output_dir_yuv)"
      ],
      "metadata": {
        "id": "64U-dffpTcmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Passo 4: Extra√ß√£o de Caracter√≠sticas Baseada em Textura (GLCM)\n",
        "\n",
        "    Agora, vamos extrair as caracter√≠sticas de textura da imagem segmentada utilizando a matriz de coocorr√™ncia de n√≠veis de cinza (GLCM)."
      ],
      "metadata": {
        "id": "XzVp8tZbvrQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√£o para calcular a GLCM e extrair propriedades de textura\n",
        "def extract_texture_features(segmented_image):\n",
        "    # Converter a imagem segmentada para escala de cinza (necess√°rio para GLCM)\n",
        "    # gray_image = rgb2gray(segmented_image) #This line is not needed since the image is already grayscale\n",
        "    gray_image = img_as_ubyte(segmented_image)  # Converter para 8 bits\n",
        "\n",
        "    # Calcular a matriz de coocorr√™ncia de n√≠veis de cinza (GLCM)\n",
        "    glcm = graycomatrix(gray_image, distances=[1], angles=[0], levels=256, symmetric=True, normed=True) #Corrected function name to graycomatrix\n",
        "\n",
        "    # Extrair propriedades de textura\n",
        "    contrast = graycoprops(glcm, 'contrast')[0, 0] #Corrected function name to graycoprops\n",
        "    correlation = graycoprops(glcm, 'correlation')[0, 0] #Corrected function name to graycoprops\n",
        "    energy = graycoprops(glcm, 'energy')[0, 0] #Corrected function name to graycoprops\n",
        "    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0] #Corrected function name to graycoprops\n",
        "\n",
        "    # Exibir as propriedades extra√≠das\n",
        "    print(f'Contraste: {contrast}')\n",
        "    print(f'Correla√ß√£o: {correlation}')\n",
        "    print(f'Energia: {energy}')\n",
        "    print(f'Homogeneidade: {homogeneity}')\n",
        "\n",
        "    return contrast, correlation, energy, homogeneity\n",
        "\n",
        "# Extrair caracter√≠sticas de textura\n",
        "texture_features = extract_texture_features(segmented_image)\n"
      ],
      "metadata": {
        "id": "C16la8JWvg42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Passo 5: Avalia√ß√£o e M√©tricas\n",
        "    \n",
        "    Ap√≥s a segmenta√ß√£o e extra√ß√£o de caracter√≠sticas, vamos avaliar o desempenho usando m√©tricas como IoU e F1-score."
      ],
      "metadata": {
        "id": "ORbadZqRvxm7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgFtYNSv7G33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1bc699f-d0a7-44f8-fd6b-cee3457effbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IoU (Jaccard): 0.10373955125384954\n",
            "F1-score: 0.18797831632653061\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.10373955125384954, 0.18797831632653061)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score, jaccard_score\n",
        "\n",
        "# Fun√ß√£o para calcular o IoU e o F1-score\n",
        "def evaluate_segmentation(segmented_image, ground_truth):\n",
        "    # Achatar as imagens segmentada e a verdade de solo\n",
        "    segmented_flat = segmented_image.flatten()\n",
        "    ground_truth_flat = ground_truth.flatten()\n",
        "\n",
        "    # Calcular o IoU (Jaccard)\n",
        "    iou = jaccard_score(ground_truth_flat, segmented_flat, average='micro')\n",
        "\n",
        "    # Calcular o F1-score\n",
        "    f1 = f1_score(ground_truth_flat, segmented_flat, average='micro')\n",
        "\n",
        "    print(f'IoU (Jaccard): {iou}')\n",
        "    print(f'F1-score: {f1}')\n",
        "\n",
        "    return iou, f1\n",
        "\n",
        "# Exemplo de uma imagem de verdade de solo (ground truth)\n",
        "ground_truth_path = 'leukemia_dataset/Segmented/Benign/WBC-Benign-001.jpg'\n",
        "ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Avaliar a segmenta√ß√£o\n",
        "evaluate_segmentation(segmented_image, ground_truth)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Passo6:  Leitura e Organiza√ß√£o dos Arquivos\n",
        "  \n",
        "  Prepara√ß√£o do Arquivo com R√≥tulos das Segmenta√ß√µes.\n",
        "  \n",
        "  Vamos organizar a leitura das imagens e os r√≥tulos a partir do CSV e da estrutura de diret√≥rios.\n",
        "\n",
        "  Estrutura de Diret√≥rios:\n",
        "    * leukemia_dataset/Segmented/Benign\n",
        "    * leukemia_dataset/Segmented/Early\n",
        "    * leukemia_dataset/Segmented/Pre\n",
        "    * leukemia_dataset/Segmented/Pro\n",
        "\n",
        "  Cada subdiret√≥rio cont√©m imagens de um tipo espec√≠fico de c√©lula, e usaremos isso para a rotulagem."
      ],
      "metadata": {
        "id": "sFLmAntZQ5pQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Definir o caminho para o dataset segmentado\n",
        "dataset_dir = 'leukemia_dataset/Segmented/'\n",
        "\n",
        "# Subdiret√≥rios de imagens segmentadas\n",
        "categories = ['Benign', 'Early', 'Pre', 'Pro']\n",
        "\n",
        "# Fun√ß√£o para carregar as imagens e seus r√≥tulos\n",
        "def load_dataset(directory, categories):\n",
        "    data = []\n",
        "\n",
        "    for category in categories:\n",
        "        category_path = os.path.join(directory, category)\n",
        "        label = category  # O r√≥tulo ser√° o nome da categoria\n",
        "\n",
        "        for filename in os.listdir(category_path):\n",
        "            img_path = os.path.join(category_path, filename)\n",
        "\n",
        "            # Adicionar a imagem e o r√≥tulo na lista\n",
        "            data.append({'filename': img_path, 'label': label})\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Carregar o dataset\n",
        "df = load_dataset(dataset_dir, categories)\n",
        "\n",
        "# Visualizar os primeiros registros\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "8ymQMKN3RDrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Passo 7: Separar o Dataset em Conjunto de Treinamento e Teste"
      ],
      "metadata": {
        "id": "Xn6YNNpucKRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir o dataset em treinamento e teste\n",
        "train_df, test_df = train_test_split(df, test_size=0.3, stratify=df['label'], random_state=42)\n",
        "\n",
        "# Exibir o n√∫mero de amostras em cada conjunto\n",
        "print(f\"N√∫mero de amostras de treinamento: {len(train_df)}\")\n",
        "print(f\"N√∫mero de amostras de teste: {len(test_df)}\")\n"
      ],
      "metadata": {
        "id": "HEL4KqklZCdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Passo 8: Segmenta√ß√£o e Extra√ß√£o de Caracter√≠sticas\n",
        "\n",
        "  Vamos aplicar a segmenta√ß√£o por limiariza√ß√£o adaptativa nas imagens e, em seguida, extrair as caracter√≠sticas usando a GLCM.\n",
        "\n",
        "  Utilizamos fun√ß√µes criadas nos passos anteriores."
      ],
      "metadata": {
        "id": "p63O2QxYcQiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.color import rgb2gray\n",
        "from skimage import img_as_ubyte\n",
        "\n",
        "\n",
        "# Fun√ß√£o para segmentar e extrair caracter√≠sticas GLCM\n",
        "def process_image(image_path):\n",
        "    # Carregar a imagem\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Segmenta√ß√£o por limiariza√ß√£o adaptativa no canal V (brilho) do HSV\n",
        "    segmented_image = adaptive_threshold_segmentation(image_rgb)\n",
        "\n",
        "    # Converter para escala de cinza (se necess√°rio)\n",
        "    # Calcular a matriz de coocorr√™ncia de n√≠veis de cinza (GLCM)\n",
        "    # Extrair propriedades de textura\n",
        "    return extract_texture_features(segmented_image)\n",
        "\n",
        "# Processar todas as imagens de treinamento e extrair caracter√≠sticas\n",
        "train_features = []\n",
        "train_labels = []\n",
        "\n",
        "for index, row in train_df.iterrows():\n",
        "    features = process_image(row['filename'])\n",
        "    train_features.append(features)\n",
        "    train_labels.append(row['label'])\n",
        "\n",
        "# Converter para arrays numpy\n",
        "X_train = np.array(train_features)\n",
        "y_train = np.array(train_labels)\n"
      ],
      "metadata": {
        "id": "84XTr9_OZGiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Passo 9: Treinamento do Classificador\n",
        "\n",
        "  Agora, vamos treinar um classificador utilizando as caracter√≠sticas extra√≠das das imagens segmentadas.\n",
        "  \n",
        "  Para isso, utilizaremos um Random Forest Classifier como exemplo."
      ],
      "metadata": {
        "id": "Hu7_WibIL6pI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Treinar o classificador\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Extrair caracter√≠sticas das imagens de teste\n",
        "test_features = []\n",
        "test_labels = []\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    features = process_image(row['filename'])\n",
        "    test_features.append(features)\n",
        "    test_labels.append(row['label'])\n",
        "\n",
        "X_test = np.array(test_features)\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "# Fazer previs√µes no conjunto de teste\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Exibir o relat√≥rio de classifica√ß√£o\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "buO8VMwiMBV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Conclus√£o etapa 1\n",
        "  \n",
        "  Segmenta√ß√£o:\n",
        "\n",
        "    Utilizamos segmenta√ß√£o adaptativa para separar as c√©lulas do fundo em imagens de sangue perif√©rico.\n",
        "\n",
        "    Extra√ß√£o de Caracter√≠sticas: Utilizamos GLCM para extrair caracter√≠sticas texturais das imagens segmentadas.\n",
        "\n",
        "    Classifica√ß√£o: Usamos um classificador Random Forest para diferenciar entre c√©lulas benignas e malignas.\n",
        "\n",
        "* Poss√≠veis Melhorias:\n",
        "  \n",
        "  Podemos ajustar o classificador, adicionar novas m√©tricas ou testar outros algoritmos para melhorar a precis√£o.\n",
        "\n",
        "  * Adotaremos o Ajustes do classificador e novas M√©tricas.\n",
        "\n",
        "  * Ajuste do Classificador: Ajustaremos os hiperpar√¢metros do Random Forest para melhorar o desempenho. Usamos GridSearchCV para encontrar os melhores par√¢metros do Random Forest, ajustando hiperpar√¢metros como n_estimators (n√∫mero de √°rvores), max_depth (profundidade m√°xima das √°rvores), e min_samples_split (n√∫mero m√≠nimo de amostras para dividir um n√≥).\n",
        "\n",
        "  * Adi√ß√£o de Novas M√©tricas: Al√©m do relat√≥rio de classifica√ß√£o, vamos adicionar m√©tricas como matriz de confus√£o, curva ROC e AUC (√Årea sob a curva ROC) para uma avalia√ß√£o mais completa.\n",
        "\n",
        "    * Relat√≥rio de Classifica√ß√£o: Fornece as m√©tricas de precis√£o, recall e F1-score para cada classe.\n",
        "    * Matriz de Confus√£o: Fornece uma visualiza√ß√£o clara de quantas predi√ß√µes foram corretas (diagonal) e quantas foram incorretas (fora da diagonal).\n",
        "    * Curva ROC e AUC: A curva ROC √© uma m√©trica importante que mostra a rela√ß√£o entre a taxa de verdadeiros positivos e falsos positivos. O AUC (√Årea sob a curva ROC) √© uma m√©trica que varia entre 0 e 1, com valores mais pr√≥ximos de 1 indicando um melhor desempenho.\n",
        "\n",
        "* Conclus√£o ap√≥s as melhorias\n",
        "\n",
        "  Random Forest Ajustado: O ajuste do classificador deve resultar em uma melhoria de desempenho.\n",
        "\n",
        "  Novas M√©tricas: A adi√ß√£o de novas m√©tricas (matriz de confus√£o, curva ROC e AUC) nos permite uma avalia√ß√£o mais robusta e visual do modelo.\n",
        "\n",
        "* Ajuste do Classificador (Random Forest)\n",
        "  \n",
        "  Vamos ajustar alguns hiperpar√¢metros do Random Forest, como o n√∫mero de estimadores e a profundidade m√°xima, para tentar melhorar o desempenho do classificador."
      ],
      "metadata": {
        "id": "sQIcOjruvMjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Definir os par√¢metros para ajuste\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Configurar o modelo Random Forest\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Configurar o GridSearch para procurar a melhor combina√ß√£o de par√¢metros\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
        "\n",
        "# Realizar o ajuste com os dados de treinamento\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Exibir os melhores par√¢metros\n",
        "print(f\"Melhores par√¢metros: {grid_search.best_params_}\")\n",
        "\n",
        "# Treinar o modelo com os melhores par√¢metros\n",
        "best_rf = grid_search.best_estimator_\n"
      ],
      "metadata": {
        "id": "-C1c0RRadCjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Previs√£o e Avalia√ß√£o com Novas M√©tricas\n",
        "\n",
        "  Agora, utilizaremos o modelo ajustado para fazer as previs√µes e, em seguida, adicionar m√©tricas como matriz de confus√£o, curva ROC, e AUC"
      ],
      "metadata": {
        "id": "Z3RgLU1kfAC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fazer as previs√µes no conjunto de teste com o modelo ajustado\n",
        "y_pred = best_rf.predict(X_test)\n",
        "y_prob = best_rf.predict_proba(X_test)[:, 1]  # Para curva ROC e AUC # Removed [:, 1] to keep all probabilities\n",
        "\n",
        "# 1. Relat√≥rio de Classifica√ß√£o\n",
        "print(\"Relat√≥rio de Classifica√ß√£o:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# 2. Matriz de Confus√£o\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Matriz de Confus√£o\")\n",
        "plt.xlabel(\"Predito\")\n",
        "plt.ylabel(\"Verdadeiro\")\n",
        "plt.show()\n",
        "\n",
        "# 3. Curva ROC e AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_prob, pos_label='Malignant')  # Assumindo 'Malignant' como a classe positiva\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Curva ROC')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Exibir o valor da AUC\n",
        "#print(f\"√Årea sob a curva ROC (AUC): {roc_auc_score(y_test, y_prob, multi_class='ovr')}\") # Added multi_class='ovr'"
      ],
      "metadata": {
        "id": "d36P1H7zfHiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercicio 2"
      ],
      "metadata": {
        "id": "4_hpCB1blJCs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercicio 3"
      ],
      "metadata": {
        "id": "pRZFkFcmlN2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercicio 4"
      ],
      "metadata": {
        "id": "BGxaJnHllZKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercicio 5"
      ],
      "metadata": {
        "id": "0ux6sjd5la1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercicio 6"
      ],
      "metadata": {
        "id": "qfreSzAolcVr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercicio 7"
      ],
      "metadata": {
        "id": "k0KsfQxBld2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercicio 8"
      ],
      "metadata": {
        "id": "6G2JWkSWlfqm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercicio 9"
      ],
      "metadata": {
        "id": "uGDNy3lDlg-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercicio 10"
      ],
      "metadata": {
        "id": "Ge7JP13bliq7"
      }
    }
  ]
}