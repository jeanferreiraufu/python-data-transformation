# -*- coding: utf-8 -*-
"""4Segmentations.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZycdQ37EjmjKxA_S3e7Az28Zhy-vGtYg
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import os
pathRaiz='/content/drive/MyDrive/MaskRcnn/Projeto_Papaya/'
os.chdir(pathRaiz)

!pip install kaggle

!pip install tf-models-official
!pip install tf-models-nightly
!pip install tensorflow-text
!pip install tensorflow-text-nightly
!pip install tf-models-no-deps

!pip install keras
!pip install patchify    #To install and import other mentioned libraries  in code
!pip install segmentation_models

!pip install "git+https://github.com/philferriere/cocoapi.git#egg=pycocotools&subdirectory=PythonAPI"

import os
import cv2
import numpy as np
from tqdm import tqdm

img_list = os.listdir("/content/drive/MyDrive/MaskRcnn/Projeto_Papaya/");

!git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git

!cd /content/drive/MyDrive/MaskRcnn/Projeto_Papaya/Monk_Object_Detection/9_segmentation_models/installation && cat requirements_colab.txt | xargs -n 1 -L 1 pip install

!unzip -qq seg_water_trained.zip

import os
import sys
sys.path.append("/content/drive/MyDrive/MaskRcnn/Projeto_Papaya/Monk_Object_Detection/9_segmentation_models/lib/");

!pip install -r requirements.txt
!pip uninstall -y keras-nightly
!pip installâ€Š--upgrade tf-nightly

from tensorflow import keras

import tensorflow as tf
from tensorflow import keras

!pip install --upgrade tensorflow

import tensorflow

!pip install numpy scipy
!pip install scikit-learn
!pip install pillow
!pip install h5py

!pip install keras

from infer_segmentation import Infer

tf = Infer();

tf = Segmenter();
#gtf = Segmenter();

classes_dict = {
    'background': 0,
    'doenca': 1
};
classes_to_train = ['background', 'doenca'];

tf.Data_Params(classes_dict, classes_to_train, image_shape=[400, 225])

!wget --load-cookies /tmp/cookies.txt "https://docs.google.com/uc?export=download&confirm=$(wget --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1FbPdoKbPn52VcmVJFRbdjD_pxcj8kWWF' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1\n/p')&id=1FbPdoKbPn52VcmVJFRbdjD_pxcj8kWWF" -O seg_water_trained.zip && rm -rf /tmp/cookies.txt

train_img_dir = "/content/drive/MyDrive/teste/root_img_dir/train_img_dir/";
train_mask_dir = "/content/drive/MyDrive/teste/root_img_dir/train_mask_dir/";

val_img_dir = "/content/drive/MyDrive/teste/root_img_dir/val_img_dir/";
val_mask_dir = "/content/drive/MyDrive/teste/root_img_dir/val_mask_dir/";

tf.Train_Dataset(train_img_dir, train_mask_dir, classes_dict, classes_to_train)
#gtf.Train_Dataset(train_img_dir, train_mask_dir, classes_dict, classes_to_train)

tf.Val_Dataset(val_img_dir, val_mask_dir)
#gtf.Val_Dataset(val_img_dir, val_mask_dir)

#gtf.List_Backbones();
tf.List_Backbones();

tf.Data_Params(batch_size=2, backbone="efficientnetb3", image_shape=[400, 225])
#gtf.Data_Params(batch_size=2, backbone="efficientnetb3", image_shape=[400, 225])

tf.List_Models();
#gtf.List_Models();

tf.Model_Params(model="Unet")
#gtf.Model_Params(model="Unet")

#gtf.Train_Params(lr=0.0001)
tf.Train_Params(lr=0.0001)

import keras
from keras.models import Sequential, Model
from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization, LeakyReLU
from keras.regularizers import l2

#import tensorflow.compat.v1 as tf
#tf.get_default_graph()"
#tf.compat.v1.get_default_graph()

import tensorflow as tf
from tensorflow import keras

tf.Setup();
#gtf.Setup();

tf.Train(num_epochs=300);
#gtf.Train(num_epochs=300);

tf.Visualize_Training_History();

tf.Model_Params(model="Unet", backbone="efficientnetb7", path_to_model='/content/drive/MyDrive/teste/root_img_dir/seg_water_trained/best_model.h5')